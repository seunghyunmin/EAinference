% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/PBsampler.R
\name{PBsampler}
\alias{PBsampler}
\title{Parameteric Bootstrapping lasso / group lasso estimator}
\usage{
PBsampler(X, PE_1, sig2_1, lbd_1, PE_2, sig2_2, lbd_2, weights = rep(1,
  max(group)), group = 1:ncol(X), niter = 2000, type, PEtype = "coeff",
  Btype = "gaussian", Y = NULL, parallel = FALSE, ncores = 2L,
  verbose = FALSE)
}
\arguments{
\item{X}{predictor matrix.}

\item{PE_1, sig2_1, lbd_1}{parameter of target distribution.
(Estimate of true coefficient or E(y) depends on \code{PEtype}, estimated variance of error, lambda).}

\item{PE_2, sig2_2, lbd_2}{additional Parameter of target distribution only
if mixture distribution is used.}

\item{weights}{weight vector in length of the number of groups. Default is
\code{rep(1, max(group))}.}

\item{group}{p x 1 vector of consecutive integers describing group structure.
The number of groups should be same as max(group). Default is \code{group = 1:p}
, where \code{p} is number of covariates.}

\item{niter}{the number of iterations.}

\item{type}{type of penalty, either to be "lasso", "grlasso", "slasso" or "sgrlasso".}

\item{PEtype}{either to be "coeff" or "mu". Decide what kind of \code{PE} to use.}

\item{Btype}{either to be "gaussian" or "wild".}

\item{Y}{response vector. This is requied when \code{Btype = "wild"}.}

\item{parallel}{logical. If \code{TRUE}, use parallelization.}

\item{ncores}{integer. The number of cores to use for the parallelization.}

\item{verbose}{verbose. This works only when
\code{parallel=FALSE}.}
}
\value{
\item{beta}{coeffieicnt estimate.}

\item{subgrad}{subgradient of coefficient.}

\item{hsigma}{standard deviation estimator, for type="slasso" or type="sgrlasso" only.}

\item{X, PE, sig2, weights, group, type, PEtype, Btype, Y, mixture}{model parameters.}
}
\description{
Draw bootstrap samples in parametric way and
derive (group) lasso estimator along with subgradient.
}
\details{
This function provides bootstrap samples for (group) lasso estimator
and its subgradient. \cr
The sampling distribution is chracterized by \code{(PE, sig2, lbd)}.
\cr First, \code{error_new} is generated from \code{N(0, sig2)}, if \code{Btype = "gaussian"}.
If \code{Btype = "wild"}, we sample \code{error_new} from the residuals
but multiply them with gaussian random variables from \code{N(0, sig2)}.
Then, \code{y_new} is generated by \code{X * PE + error_new},
if \code{PEtype = "coeff"}, or \code{PE + error_new}, if \code{PEtype = "mu"}.
See Zhou(2014) and Zhou and Min(2016) for more details.

Four distict penalties can be used; \code{"lasso"} for lasso, \code{"grlasso"} for group lasso,
\code{"slasso"} for scaled lasso and \code{"sgrlasso"} for scaled group lasso.

If non-mixture distribution is used, the distribution with parameters \code{(PE_1, sig2_1, lbd_1)}
will be used.
If one uses mixture distribution by providing \code{(PE_2, sig2_2, lbd_2)},
with 1/2 chance, samples will be drawn from the distribution with
(PE_1, sig2_1, lbd_1) and with another 1/2 chance, they will be drawn from
the distribution with (PE_2, sig2_2, lbd_2).
}
\examples{
set.seed(1234)
n <- 10
p <- 30
Niter <-  10
Group <- rep(1:(p/10), each = 10)
Weights <- rep(1, p/10)
x <- matrix(rnorm(n*p), n)
#
# Using non-mixture distribution
#
PBsampler(X = x, PE_1 = rep(0, p), sig2_1 = 1, lbd_1 = .5,
 weights = Weights, group = Group, type = "grlasso", niter = Niter, parallel = FALSE)
PBsampler(X = x, PE_1 = rep(0, p), sig2_1 = 1, lbd_1 = .5,
 weights = Weights, group = Group, type = "grlasso", niter = Niter, parallel = TRUE)
#
# Using mixture distribution
#
PBsampler(X = x, PE_1 = rep(0, p), sig2_1 = 1, lbd_1 = .5,
 PE_2 = rep(1, p), sig2_2 = 2, lbd_2 = .3, weights = Weights,
 group = Group, type = "grlasso", niter = Niter, parallel = TRUE)
}
\references{
Zhou, Q. (2014). Monte Carlo simulation for Lasso-type problems by estimator augmentation.
Journal of the American Statistical Association, 109: 1495-1516.

Zhou, Q. and Min, S. (2017). Estimator augmentation with applications in
high-dimensional group inference. Electronic Journal of Statistics, accepted.
}
