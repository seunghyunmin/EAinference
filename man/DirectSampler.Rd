% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/DirectSampler.R
\name{DirectSampler}
\alias{DirectSampler}
\title{Bootstrapping lasso / group lasso estimator}
\usage{
DirectSampler(X, pointEstimate_1, sig2_1, lbd_1, pointEstimate_2, sig2_2, lbd_2,
  weights = rep(1, max(group)), group = 1:ncol(X), niter = 2000,
  type = "coeff", method = "normal", Y, parallel = FALSE, ncores = 2L,
  verbose = FALSE)
}
\arguments{
\item{X}{Predictor matrix.}

\item{pointEstimate_1, sig2_1, lbd_1}{Parameter of target distribution.
(coefficient estimate, estimated variance of error, lambda). Not required for
\code{method = "normal"}.}

\item{pointEstimate_2, sig2_2, lbd_2}{Additional Parameter of target distribution only
if mixture distribution is used. Not required for \code{method = "normal"}.}

\item{weights}{Weight vector in length of the number of groups. Default is
\code{rep(1, max(group))}.}

\item{group}{p x 1 vector of consecutive integers describing group structure.
The number of groups should be same as max(group). Default is \code{group = 1:p}
, where \code{p} is number of covariates.}

\item{niter}{The number of iterations.}

\item{method}{Bootstrap method, one of \code{"normal"} or \code{"nonparametric"}.
If \code{"normal"}, resample errors from normal distiribution. If \code{"nonparametric"},
resample errors from residuals.}

\item{Y}{Response vector. Needed only if \code{method="nonparametric"}.}

\item{parallel}{Logical. If \code{TRUE}, use parallelization.}

\item{ncores}{Integer. The number of cores to use for the parallelization.}

\item{verbose}{Whether to show the process. Default is FALSE. Only works when
parallel=FALSE.}
}
\value{
\item{beta}{(group) lasso estimator.}

\item{subgrad}{subgradient.}

\item{X, pointEstimate, sig2, weights, group, method, type, mixture}{Model parameters}
}
\description{
Draw bootstrap samples in parametric or nonparametric way and
derive (group) lasso estimator along with subgradient.
}
\details{
This function provides bootstrap samples for (group) lasso estimator
and its subgradient. The sampling distribution is chracterized by \code{(pointEstimate, sig2, lbd)}.
First, we generate \code{y_new} by \code{X * pointEstimate + error_new}, while \code{error_new}
is generated by two distinct ways.
If \code{method="normal"}, error_new is generated from N(0, sig2).
If \code{method="nonparametric"}, error_new is resampled from the residuals,
y - X*pointEstimate. See Zhou(2014) and Zhou and Min(2016) for more details.

If non-mixture distribution is used, the distribution with parameters \code{(pointEstimate_1, sig2_1, lbd_1)}
will be used.
If one uses mixture distribution by providing \code{(pointEstimate_2, sig2_2, lbd_2)},
with 1/2 chance, samples will be drawn from the distribution with
(pointEstimate_1, sig2_1, lbd_1) and with another 1/2 chance, they will be drawn from
the distribution with (pointEstimate_2, sig2_2, lbd_2).
}
\examples{
set.seed(1234)
n <- 10
p <- 30
Niter <-  10
Group <- rep(1:(p/10), each = 10)
Weights <- rep(1, p/10)
x <- matrix(rnorm(n*p), n)
#
# Using non-mixture distribution
#
DirectSampler(X = x, pointEstimate_1 = rep(0, p), sig2_1 = 1, lbd_1 = .5,
 weights = Weights, group = Group, niter = Niter, parallel = FALSE)
DirectSampler(X = x, pointEstimate_1 = rep(0, p), sig2_1 = 1, lbd_1 = .5,
 weights = Weights, group = Group, niter = Niter, parallel = TRUE)
#
# Using mixture distribution
#
DirectSampler(X = x, pointEstimate_1 = rep(0, p), sig2_1 = 1, lbd_1 = .5,
 pointEstimate_2 = rep(1, p), sig2_2 = 2, lbd_2 = .3, weights = Weights,
 group = Group, niter = Niter, parallel = TRUE)
}
